{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\">\n",
    "<b>Привет, Ларин!</b>\n",
    "\n",
    "Меня зовут Александр Пономаренко, и я буду проверять твой проект. Предлагаю общаться на «ты» :) Но если это не удобно - дай знать, и мы перейдем на \"вы\". \n",
    "\n",
    "Моя основная цель — не указать на совершенные тобою ошибки, а поделиться своим опытом и помочь тебе стать data science. Ты уже проделал большую работу над проектом, но давай сделаем его еще лучше. Ниже ты найдешь мои комментарии - **пожалуйста, не перемещай, не изменяй и не удаляй их**. Увидев у тебя ошибку, в первый раз я лишь укажу на ее наличие и дам тебе возможность самой найти и исправить ее. На реальной работе твой начальник будет поступать так же, а я пытаюсь подготовить тебя именно к работе аналитиком. Но если ты пока не справишься с такой задачей - при следующей проверке я дам более точную подсказку. Я буду использовать цветовую разметку:\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Комментарий ревьюера ❌:</b> Так выделены самые важные замечания. Без их отработки проект не будет принят. </div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера ⚠️:</b> Так выделены небольшие замечания. Я надеюсь, что их ты тоже учтешь - твой проект от этого станет только лучше. Но настаивать на их отработке не буду.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Так я выделяю все остальные комментарии.</div>\n",
    "\n",
    "Давай работать над проектом в диалоге: **если ты что-то меняешь в проекте или отвечаешь на мои комменатри — пиши об этом.** Мне будет легче отследить изменения, если ты выделишь свои комментарии:\n",
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Например, вот так.</div>\n",
    "\n",
    "Всё это поможет выполнить повторную проверку твоего проекта оперативнее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: black; background-color: #FFC373; padding: 10px 20px;\">\n",
    "Привет Понамаренко <br>\n",
    "Фамилии хорошо, предпочитаю по имени<br>\n",
    "Александр спасибо за проверку работы)<br>\n",
    "Хорошо, что ты не выполнял сцену, а то была бы ошибка) заметил спустя 10 мин как отправил<br>\n",
    "Но было поздно<br>\n",
    "Мне всё понятно вопросов по теме нет <br>\n",
    "Один не по теме<br>\n",
    "Мы знакомы? \n",
    "Сразу такое ощущение возникает когда фамильярничают!<br> \n",
    "    <br> \n",
    "Ещё вопрос, ниже в комментарии пишешь +лайк за прогрев<br> \n",
    "    Что имеешь ввиду?<br> \n",
    "    Наверное это относится к batch_size?!\n",
    "    \n",
    "Поправил твои замечания не все сработали\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Цель\" data-toc-modified-id=\"Цель-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Цель</a></span></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#DistilBertForSequenceClassification\" data-toc-modified-id=\"DistilBertForSequenceClassification-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>DistilBertForSequenceClassification</a></span></li><li><span><a href=\"#вывод\" data-toc-modified-id=\"вывод-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>вывод</a></span></li><li><span><a href=\"#LogisticRegression-TF-IDF\" data-toc-modified-id=\"LogisticRegression-TF-IDF-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>LogisticRegression TF-IDF</a></span></li><li><span><a href=\"#вывод\" data-toc-modified-id=\"вывод-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>вывод</a></span></li></ul></li><li><span><a href=\"#Выводы-финал\" data-toc-modified-id=\"Выводы-финал-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы финал</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цель\n",
    "\n",
    "Для интернет-магазина \"Викишоп\" подготовить модель фильтрации комментариев и описания товаров<br>\n",
    "Модель должна классифицировать тексты определяя эмоциональный окрас позитивный или негативный <br>\n",
    "<br>\n",
    "Критерий оценки качества модели метрика F1, допустимые минимальные значения 0.75<br>\n",
    "Данные находятся по ссылке https://code.s3.yandex.net/datasets/toxic_comments.csv<br>\n",
    "В файле два столбца `text и toxic` <br>\n",
    "Признаки находятся в столбце `text`<br>\n",
    "Целевой признак `toxic`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/maximlarin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/maximlarin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "capture": "ExecutionMagics",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "markdown": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autoawait": "AsyncMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cat": "Other",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "colors": "BasicMagics",
        "conda": "PackagingMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "cp": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "lf": "Other",
        "lk": "Other",
        "ll": "Other",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "lx": "Other",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "man": "KernelMagics",
        "matplotlib": "PylabMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "mv": "Other",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "pip": "PackagingMagics",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rm": "Other",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "store": "StoreMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %colors  %conda  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%capture  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import torch\n",
    "import requests\n",
    "import transformers \n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, DistilBertConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Загрузка стоп-слов\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import  f1_score, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "except:\n",
    "    !pip install optuna\n",
    "    import optuna\n",
    "\n",
    "\n",
    "try:\n",
    "    import pkg_resources\n",
    "except:\n",
    "    !pip install pkg_resources\n",
    "    import optuna  \n",
    "\n",
    "%lsmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека `transformers` версии 4.12.5 требует версию `protobuf` 3.19.0 или меньше, и может не работать с более новыми версиями `protobuf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U protobuf==3.19.0\n",
    "\n",
    "if pkg_resources.get_distribution(\"protobuf\").version < '3.19.0':\n",
    "    !pip install -U protobuf==3.19.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaded = False\n",
    "try:\n",
    "    data = pd.read_csv('toxic_comments.csv')\n",
    "    data_loaded = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if not data_loaded:\n",
    "    data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Огонь, данные на месте:)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим константы\n",
    "NAME_DATA = 'toxic_commens'\n",
    "RANDOM_STATE = 6568\n",
    "SAMPLE_SIZE = 5000 # Размер выборки корпуса - 1000 на i5 общитывает на cpu ≈ 60 мин\n",
    "                    # на gpu ≈ 5 мин\n",
    "                     # Размер выборки корпуса - 5000 на i5 общитывает на cpu ≈ 11 часов\n",
    "                    # на gpu ≈ 60 мин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения работы мы будем использовать модель DistilBertForSequenceClassification<br>\n",
    "Модель принимает на вход векторы максимальной длины 512 токенов <br>\n",
    "Посчитаем сколько текстов превышает эту величину и отфильтруем корпус текстов<br>\n",
    "Это поможет избежать танца с бубном вокруг подачи на вход векторов для модели DistilBertForSequenceClassification  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент текстов от общей длины корпуса с размером больше 512 токенов 1.74%\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем токенизатор\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "# Токенизируем каждый текст и подсчитываем количество слов\n",
    "data['word_count'] = data['text'].apply(lambda x: len(tokenizer.tokenize(x.lower())))\n",
    "\n",
    "long_text = (data.loc[data['word_count'] >= 512]['word_count']).count()\n",
    "print(f'Процент текстов от общей длины корпуса с размером больше 512 токенов {long_text/data.shape[0]:,.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Еще можно вот так:\n",
    "    \n",
    "```python \n",
    "    from torch.nn.utils.rnn import pad_sequence\n",
    "    from tqdm import tqdm\n",
    "    tqdm.pandas()\n",
    "\n",
    "    tokenized = data['text'].progress_apply(\n",
    "    lambda x: tokenizer.encode(x, max_length=512, truncation=True, add_special_tokens=True)) #обрежет под нужное кол-во токенов\n",
    "    \n",
    "    padded = pad_sequence([torch.as_tensor(seq) for seq in tokenized], batch_first=True) #добьет нулями  \n",
    "    \n",
    "    attention_mask = padded > 0\n",
    "    attention_mask = attention_mask.type(torch.LongTensor) #Тут можно сделать, то как было в теории\n",
    "```\n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, смело можем отсечь эти тексты так как их количество невелико "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['word_count'] < 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isna_count_procent(data, name):\n",
    "    '''\n",
    "    Создадим таблицу с пропусками в  дата сете\n",
    "    Всего три столбца \n",
    "    1. процентное отношение пропусков к длине\n",
    "    2. количество пропусков в единицах\n",
    "    3. тип\n",
    "    Далее блок выводит всю доступную информацию о данных \n",
    "    Несколько первых строк\n",
    "    Описание числовых признаков\n",
    "    Описание категориальных признаков\n",
    "    \n",
    "    '''\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    isna_columns = data.isna().sum() > 0\n",
    "    type_ = pd.DataFrame(data[data.isna().sum()[isna_columns].index.tolist()].dtypes)[0]\n",
    "    isna_columns = pd.DataFrame([data.isna().sum()[isna_columns]/data.shape[0], data.isna().sum()[isna_columns]]).T\n",
    "    isna_columns = isna_columns.rename(columns={0: 'procent', 1: 'count'})\n",
    "    # isna_columns['type'] = type_[0]\n",
    "    isna_columns['count'] = isna_columns['count'].map('{:,.2f}'.format)\n",
    "    isna_columns['procent'] = isna_columns['procent'].map('{:,.2%}'.format)\n",
    "    isna_columns = isna_columns.sort_values('procent', ascending=False)\n",
    "    # блок показывае всё о данных\n",
    "    display(data.head())\n",
    "    print('#'*55)\n",
    "    print()\n",
    "    display(data.describe(include=np.number))\n",
    "    print()\n",
    "    display(data.describe(include=np.object_))\n",
    "    print('#'*55)\n",
    "    print()\n",
    "    data.info()\n",
    "    print('#'*55)\n",
    "    isna = data.isna().sum().sum()\n",
    "    isna_procent = len(isna_columns)/data.shape[1]\n",
    "    s = data.duplicated().sum()\n",
    "    print(f'Количество дубликатов в данных  равно {s}')\n",
    "    print()\n",
    "    print(f'Всего пропусков в {name} {isna:,} шт. в {len(isna_columns)} столбцах')\n",
    "    print(f'В процентном отношении {isna_procent:.2%} от {data.shape[1]:,} признаков')\n",
    "  \n",
    "    print()\n",
    "    display(isna_columns)\n",
    "    return isna_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic  \\\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1           1  D'aww! He matches this background colour I'm s...      0   \n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   word_count  \n",
       "0          60  \n",
       "1          32  \n",
       "2          50  \n",
       "3         131  \n",
       "4          19  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156517.000000</td>\n",
       "      <td>156517.000000</td>\n",
       "      <td>156517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79743.816212</td>\n",
       "      <td>0.101638</td>\n",
       "      <td>70.324712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46028.945487</td>\n",
       "      <td>0.302172</td>\n",
       "      <td>77.523461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39881.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79761.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119610.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159450.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>511.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0          toxic     word_count\n",
       "count  156517.000000  156517.000000  156517.000000\n",
       "mean    79743.816212       0.101638      70.324712\n",
       "std     46028.945487       0.302172      77.523461\n",
       "min         0.000000       0.000000       1.000000\n",
       "25%     39881.000000       0.000000      21.000000\n",
       "50%     79761.000000       0.000000      43.000000\n",
       "75%    119610.000000       0.000000      88.000000\n",
       "max    159450.000000       1.000000     511.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>156517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Good point. Just that the math for the first d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "count                                              156517\n",
       "unique                                             156517\n",
       "top     Good point. Just that the math for the first d...\n",
       "freq                                                    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 156517 entries, 0 to 159291\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  156517 non-null  int64 \n",
      " 1   text        156517 non-null  object\n",
      " 2   toxic       156517 non-null  int64 \n",
      " 3   word_count  156517 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 6.0+ MB\n",
      "#######################################################\n",
      "Количество дубликатов в данных  равно 0\n",
      "\n",
      "Всего пропусков в toxic_commens 0 шт. в 0 столбцах\n",
      "В процентном отношении 0.00% от 4 признаков\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>procent</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [procent, count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>procent</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [procent, count]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isna_count_procent(data, NAME_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных два столбца которые мы ожидали увидеть и <br>\n",
    "Третий столбец о которм заказчик нас не предупредил<br>\n",
    "Проверим является ли столбец `Unnamed: 0` индексом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Столбец не является непрерывным.\n"
     ]
    }
   ],
   "source": [
    "column_array = np.array(data['Unnamed: 0'])\n",
    "\n",
    "# Вычисление разностей между элементами массива\n",
    "diff_array = np.diff(column_array)\n",
    "\n",
    "# Проверка на непрерывность\n",
    "if np.all(diff_array == 1):\n",
    "    print(\"Столбец является непрерывным.\")\n",
    "else:\n",
    "    print(\"Столбец не является непрерывным.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация в столбце `Unnamed: 0` не понятна ценности для выполнения задания не составляет<br>\n",
    "Удалим этот столбец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns='Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Хорошо\n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['text.color'] = 'black'\n",
    "\n",
    "fig, (ax1) = plt.subplots( figsize=(8,6));\n",
    "fig.patch.set_facecolor('#A0DFE2')\n",
    "data['toxic'].value_counts().plot.pie( labels=None, ylabel='', autopct='%1.2f%%', legend=True, ax=ax1);\n",
    "ax1.legend(['положительный', 'отрицательный'],loc='lower left');\n",
    "ax1.set_title('Количество положительных и отрицательных текстов');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевой признак имеет большую диспропорцию, при разбиении на обучающую и проверочную выборки обязательно <br>\n",
    "Выполнить балансировку классов\n",
    "\n",
    "Для выполнения нашего проекта нам понадобиться причесанный текс в двух конфигурациях<br>\n",
    "В одной без лемматизации для модели BERT<br>\n",
    "В другой с лемматизацией для построения векторов TF-IDF в sklearn<br>\n",
    "Напишем функцию, выполним обработку текста и сохраним результат в файл csv <br>\n",
    "В дальнейшем будем инициировать корпус из подготовленного файла<br>\n",
    "\n",
    "Это поможет избежать многократной обработки и ускорит выполнение проекта<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text, lemma=True):\n",
    "    # Проверка на тип строки\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    \n",
    "    # Удаление знаков препинания\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Приведение текста к нижнему регистру\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Токенизация текста\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Оптимизация: кэширование множества стоп-слов\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Фильтрация стоп-слов и лемматизация текста (если значение lemma равно True)\n",
    "    stemmer = SnowballStemmer('english') if lemma else None\n",
    "    filtered_tokens = []\n",
    "    for word in tokens:\n",
    "        if word not in stop_words:\n",
    "            if stemmer is not None:\n",
    "                word = stemmer.stem(word)\n",
    "            filtered_tokens.append(word)\n",
    "    \n",
    "    text = ' '.join(filtered_tokens)\n",
    " \n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b>\n",
    "Так же можешь попробовать использовать spacy:\n",
    "    \n",
    "```python\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatize_spacy(text):\n",
    "    return \" \".join([token.lemma_ for token in nlp(text)])\n",
    "\n",
    "data['lemm_spacy'] = data['text'].progress_apply(lemmatize_spacy)     \n",
    "```\n",
    "\n",
    "Вот так можно следить за выполнением функции (как раз выше его использовал)\n",
    "\n",
    "```python\n",
    "    \n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "data['text'] = data['text'].progress_apply(lemmatize_text) \n",
    "```\n",
    "Где *lemmatize_text* - функция\n",
    "\n",
    "    \n",
    "P.S Кстати можно ускорить spacy ( раз в 5 +-)\n",
    "    \n",
    "```python\n",
    "new_corpus = []\n",
    "\n",
    "for doc in tqdm(nlp.pipe(data['text'], batch_size=64, n_process=-1, disable=[\"parser\", \"ner\"]), total=len(data['text'])):\n",
    "    word_list = [tok.lemma_ for tok in doc]\n",
    "    new_corpus.append(' '.join(word_list))\n",
    "    \n",
    "data['lemm_spacy_new'] = new_corpus   \n",
    "    \n",
    "    \n",
    "```\n",
    "    \n",
    "Для больших объемов текста ```SpaCy``` рекомендует использовать ```nlp.pipe```, который может работать в пакетах ```batch_size```(Допустим ```batch_size=64```, тогда все наши данные делятся на 64 пакета (как прям в фолдах, только там мы пишем число на сколько поделить наши данные (3/5/10 частей),а тут пишем, сколько данных отдать в обработку)  и имеет встроенную поддержку многопроцессорной обработки ```n_process``` (аналог ```n_jobs``` для GridSearchCV).\n",
    "\n",
    "Кроме того, нужно убедиться, что мы отключили все элементы конвейера, которые мы не планируем использовать, поскольку они просто потратят время на обработку. Если мы выполняем только лемматизацию, то необходимо передать ```disable=[\"parser\", \"ner\"]``` к ```nlp.pipe```.\n",
    "    \n",
    "    \n",
    "P.S.S Если запустишь ```nlp.pipe```, то первое время нужно подождать прежде, чем начнется обработка \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: black; background-color: #FFC373; padding: 10px 20px;\">\n",
    "Реализовал твоё предложение в результате время выполнения увеличилось в три четыре раза +- <br>\n",
    "Забавно вышло, предлагаю рассмотреть мой код и его рекомендовать как оптимизированный по скорости &#128526;<br><br>\n",
    "    \n",
    "<img src=\"https://media.discordapp.net/attachments/1087844810653712394/1096207772577701978/Screenshot_2023-04-14_at_01.54.24.png\" alt=\"description of image\" width=\"683\" height=\"425\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156517it [01:06, 2366.02it/s]\n",
      "156517it [02:01, 1287.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min, sys: 9.71 s, total: 3min 9s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['processed_text'] =  list(tqdm(map(lambda x: preprocess_text(x, lemma=False), data['text'])))\n",
    "data['lemma_text'] =  list(tqdm(map(lambda x: preprocess_text(x, lemma=True), data['text'])))\n",
    "\n",
    "filtered_data = data[(data['processed_text'].notnull()) & (data['processed_text']!='') & \n",
    "                     (data['lemma_text'].notnull()) & (data['lemma_text']!='')].copy()\n",
    "filtered_data.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>lemma_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>explan edit made usernam hardcor metallica fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>daww matches background colour im seemingly st...</td>\n",
       "      <td>daww match background colour im seem stuck tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>hey man im really trying edit war guy constant...</td>\n",
       "      <td>hey man im realli tri edit war guy constant re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>cant make real suggestions improvement wondere...</td>\n",
       "      <td>cant make real suggest improv wonder section s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>sir hero chance remember page thats</td>\n",
       "      <td>sir hero chanc rememb page that</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  word_count  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0          60   \n",
       "1  D'aww! He matches this background colour I'm s...      0          32   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0          50   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0         131   \n",
       "4  You, sir, are my hero. Any chance you remember...      0          19   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  explanation edits made username hardcore metal...   \n",
       "1  daww matches background colour im seemingly st...   \n",
       "2  hey man im really trying edit war guy constant...   \n",
       "3  cant make real suggestions improvement wondere...   \n",
       "4                sir hero chance remember page thats   \n",
       "\n",
       "                                          lemma_text  \n",
       "0  explan edit made usernam hardcor metallica fan...  \n",
       "1  daww match background colour im seem stuck tha...  \n",
       "2  hey man im realli tri edit war guy constant re...  \n",
       "3  cant make real suggest improv wonder section s...  \n",
       "4                    sir hero chanc rememb page that  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_data = pd.read_csv('processed_data.csv') \n",
    " \n",
    "bert_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "Заказчик предоставил csv файл с тремя столбцами `Unnamed: 0, text, toxic`<br>\n",
    "Столбец `Unnamed: 0` удалили он нам не нужен для выполнения работы<br>\n",
    "Столбец `text` это признак, столбец `toxic` целевой признак <br>\n",
    "\n",
    "Для выполнения работы будем использовать модель DistilBertForSequenceClassification<br>\n",
    "Модель принимает на вход векторы максимальной длины 512 токенов <br>\n",
    "Отфильтровали все тексты длина которых превышала 512токенов<br>\n",
    "Это поможет избежать танца с бубном вокруг подачи на вход векторов для модели DistilBertForSequenceClassification  <br>\n",
    "\n",
    "Целевой признак имеет большую диспропорцию, при разбиении на обучающую и проверочную выборки, обязательно <br>\n",
    "Выполнить балансировку классов\n",
    "\n",
    "Выполнили обработку текста с лемматизацией и без<br>\n",
    "Текст без лемматизации для модели BERT<br>\n",
    "Текст с лемматизацией для построения векторов TF-IDF в sklearn<br>\n",
    "\n",
    "Подготовленный текс сохранили в  файл `processed_data.csv`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для реализации работы по созданию модели бинарной классификации используем пред обученную модель DistilBertForSequenceClassification<br>\n",
    "С сайта [huggingface.co](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)<br>\n",
    "Для неё нам понадобится причёсанный текст без лемматизации из столбца `processed_text` <br>\n",
    "Далее мы возьмем небольшой кусочек корпуса для примера того, что код работает корректо<br>\n",
    "И до обучим модель с учителем, что позволит ей лучше понять классификацию нашего корпуса<br>\n",
    "Полное обучение модели мы провели на подходящем оборудовании на сайте [kaggle](https://www.kaggle.com/code/maksimlarin/neironver2/notebook?scriptVersionId=125267350)<br>Поэтому для примера нам хватит небольшого количества текстов<br>\n",
    "Далее для классификации будем инициировать модель и её конфигурационный файл из сохранённых после полного обучения файлов "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция создаёт директории \n",
    "def dir_make(dir_name):\n",
    "     # определим путь к директории\n",
    "    directory = os.path.abspath(dir_name)\n",
    "\n",
    "    # проверим, существует ли директория, и создадим ее, если это необходимо\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    return directory \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выберем не много для примера\n",
    "bert_data_base = bert_data[['processed_text', 'toxic']].sample(n=SAMPLE_SIZE, replace=False).reset_index(drop=True).copy()\n",
    "\n",
    "bert_data_base.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b>\n",
    "Хорошо \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициируем модель `DistilBertForSequenceClassification`, токенизатор и определитель устройства для расчетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделение на тренировочный и тестовый наборы данных\n",
    "train_data, test_data = train_test_split(bert_data_base, test_size=0.2, random_state=42, stratify=bert_data_base['toxic'])\n",
    "\n",
    "train_data_token = tokenizer.batch_encode_plus(train_data['processed_text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "test_data_token = tokenizer.batch_encode_plus(test_data['processed_text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# объединение закодированных тензоров и меток в один TensorDataset\n",
    "dataset_train_data = TensorDataset(train_data_token['input_ids'], train_data_token['attention_mask'], torch.tensor(train_data['toxic'].values))\n",
    "dataset_test_data = TensorDataset(test_data_token['input_ids'], test_data_token['attention_mask'], torch.tensor(test_data['toxic'].values))\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=2, num_training_steps=len(train_data)*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Да, хорошая идея использовать Dataloader + лайк за прогрев \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация DataLoader\n",
    "batch_size = 20 # количество элементов в батче\n",
    "train_loader = DataLoader(dataset_train_data, batch_size=batch_size)\n",
    "model.to(device)\n",
    "\n",
    "# цикл обучения\n",
    "for epoch in range(3):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm(train_loader):\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "       \n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print('Epoch:', epoch+1, 'Training Loss:', f'{avg_train_loss:,.3f}')\n",
    "   \n",
    "    test_loader = DataLoader(dataset_test_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for batch in tqdm(test_loader):\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predicted_label = torch.argmax(outputs[0], dim=1).cpu().numpy()\n",
    "            true_label = labels\n",
    "            y_pred.extend(predicted_label.tolist())\n",
    "            y_true.extend(true_label.tolist())\n",
    "\n",
    "        print('Epoch:', epoch+1, 'F1:', f'{f1_score(y_true, y_pred):,.3f}')\n",
    "        \n",
    "        \n",
    "exam_fale = dir_make('exam_fale')\n",
    "        \n",
    "model.to(torch.device('cpu'))\n",
    "model_file = os.path.join(exam_fale, \"model_epoch_3_exam.pth\")\n",
    "torch.save(model.state_dict(), model_file)\n",
    "\n",
    "\n",
    "# Сохранение конфигурации модели\n",
    "\n",
    "config_file = os.path.join(exam_fale, \"config_epoch_3_exam.jso\")\n",
    "model.config.to_json_file(config_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель `DistilBertForSequenceClassification` до обучили на небольшой выборке подготовленных текстов<br>\n",
    "Напишем функцию классификации текста, она принимает на вход модель, таблицу с подготовленным текстом и таргетом<br>\n",
    "Возвращает туже таблицу с новым столбцом значение которого это классификация предсказанная моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classifiction_corpus(model, processed_text, column_name):    \n",
    "    encoded_texts = (tokenizer.batch_encode_plus(processed_text['processed_text'].tolist(), \n",
    "                                                 padding=True, truncation=True, return_tensors='pt').to(device))\n",
    "\n",
    "    batch_size = 10\n",
    "\n",
    "    # Инициализация пустого тензора для хранения предсказанных классов\n",
    "    predicted_classes = torch.empty((len(encoded_texts['input_ids']),), dtype=torch.long)\n",
    "    model.to(device)\n",
    "    # Передача данных порциями в модель\n",
    "    for i in tqdm(range(0, len(encoded_texts['input_ids']), batch_size)):\n",
    "        inputs_pred = {\n",
    "            'input_ids': encoded_texts['input_ids'][i:i+batch_size],\n",
    "            'attention_mask': encoded_texts['attention_mask'][i:i+batch_size],\n",
    "        }\n",
    "        outputs_pred = model(**inputs_pred)\n",
    "\n",
    "        batch_predicted_classes = torch.argmax(outputs_pred.logits, dim=-1)\n",
    "        predicted_classes[i:i+batch_size] = batch_predicted_classes\n",
    "\n",
    "    processed_text[column_name] = torch.tensor(predicted_classes).cpu().to(torch.long)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним классификацию до обученной моделью `DistilBertForSequenceClassification` на небольшом корпусе текстов<br>\n",
    "Который выберем случайным образом из генерального корпуса, для чистоты эксперимента "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Выберем не много для примера\n",
    "bert_data_base = bert_data[['processed_text', 'toxic']].sample(n=SAMPLE_SIZE, replace=False).reset_index(drop=True).copy()\n",
    "\n",
    "bert_data_base = classifiction_corpus(model, bert_data_base, 'predicted_classes_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы до обучили модель DistilBertForSequenceClassification на небольшом корпусе текста для примера<br>\n",
    "И получили конфигурационный файл модели `config_epoch_3_exam.jso` и файл с весами `model_epoch_3_exam.pth`<br>\n",
    "Файлы поместили в директорию `exam_fale`<br>\n",
    "Полное до обучение модели выполнили на сайте `kaggle` и уже имеем готовые конфигурационные файлы<br>\n",
    "Которые будем использовать для инициализации модели<br>\n",
    "Notebook с полным дообучением можно посмотреть по ссылке [kaggle notebook continuing education](https://www.kaggle.com/code/maksimlarin/neironver2/notebook)<br>\n",
    "Файлы конфигурации находятся на google disk и для того, что бы их от туда взять напишем функцию парсера и создадим директорию для файлов<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция скачивает файлы конфигурвции с google drive\n",
    "def drive_parser(url, fale_name, dir_name):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    download_form = soup.find('form', {'id': 'download-form'})\n",
    "    download_url = download_form.attrs['action']\n",
    "\n",
    "    data = {}\n",
    "    for input_tag in download_form.find_all('input'):\n",
    "        name = input_tag.attrs.get('name')\n",
    "        value = input_tag.attrs.get('value')\n",
    "        if name and value:\n",
    "            data[name] = value\n",
    "\n",
    "    response = requests.post(download_url, data=data)\n",
    "\n",
    "     #  путь к директории\n",
    "    directory = dir_make(dir_name)\n",
    "\n",
    "        # сохраним файл в директории\n",
    "    with open(os.path.join(directory, fale_name), 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция скачивает файлы конфигурвции с google drive\n",
    "def get_json(url, fale_name, dir_name):\n",
    "    \n",
    "     # определим путь к директории\n",
    "    directory = dir_make(dir_name)\n",
    "\n",
    "    # отправим GET-запрос к URL-адресу файла\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # сохраним содержимое файла\n",
    "    with open(os.path.join(directory, fale_name), 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим репозиторий `files_from_drive`, скачаем в него файлы конфигурации модели которые получили после до обучения <br>\n",
    "Модели DistilBertForSequenceClassification на полном корпусе текстов<br>\n",
    "Инициируем модель с конфигурацией которую скачали и выполним классификацию текстов для сравнения<br>\n",
    "Качества до обученной модели на не большом корпусе и качество F1 которую показала модель <br>\n",
    "До обученная на 80% от полного корпуса текстов классифицируя полный корпус текста<br>\n",
    "Полную классификацию текста с до обученной моделью выполнили на сайте `Keggle`<br>\n",
    "Ноутбук с работой доступен по ссылке [kaggle классификация полного корпуса](https://www.kaggle.com/code/maksimlarin/building-f1)<br><br>\n",
    "Инициируем переменную с названием директории для скачивания готовой конфигурации<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dir_name = 'files_from_drive'\n",
    "\n",
    "drive_parser('https://drive.google.com/u/0/uc?id=1VJ6qTSLny5wkwsLon41_nqZazi-Jf2UD&export=download', 'model_epoch_3_drive.pth', dir_name)\n",
    "drive_parser('https://drive.google.com/uc?id=1H0lZAmi5Dq-Yi7j9QSjvADWxzxWz9Dhl&export=download', 'processed_data_drive.csv', dir_name)\n",
    "get_json('https://drive.google.com/uc?id=1cZUpJ1odjfqdSskpTiHqc9COOBvz39Im&export=download', 'config_epoch_3_drive.json', dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициируем модель `DistilBertForSequenceClassification` с готовой конфигурацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_model = 'files_from_drive/model_epoch_3_drive.pth' #  путь к файлу \n",
    "\n",
    "path_to_config = 'files_from_drive/config_epoch_3_drive.json' #  путь к файлу \n",
    "with open(path_to_config, 'r') as f:\n",
    "    config_dict = json.load(f)\n",
    "config = DistilBertConfig.from_dict(config_dict)\n",
    "\n",
    "# Создание модели на основе файла конфигурации и загруженных весов\n",
    "model_ful = DistilBertForSequenceClassification(config=config)\n",
    "model_ful.load_state_dict(torch.load(path_to_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним классификацию до обученной моделью DistilBertForSequenceClassification на маленьком корпусе текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Выберем не много для примера\n",
    "bert_data_fit = bert_data[['processed_text', 'toxic']].sample(n=SAMPLE_SIZE, replace=False).reset_index(drop=True).copy()\n",
    "\n",
    "\n",
    "bert_data_fit = classifiction_corpus(model_ful, bert_data_fit, 'predicted_classes_fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим таблицу с классификацией по полному корпусу<br>\n",
    "Посчитаем качество модели используя метрику f1 и заполним финальную таблицу с результатом<br>\n",
    "Для модели до обученной на небольшом корпусе текстов<br>\n",
    "Для модели обученной на 80% от всего корпуса и выполняющей классификацию небольшого корпусе<br>\n",
    "Для модели обученной на 80% от всего корпуса и выполняющей классификацию полного корпуса текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_full_classes = pd.read_csv('files_from_drive/processed_data_drive.csv')\n",
    "\n",
    "\n",
    "distilBert_full_f1 = f1_score(predicted_full_classes['toxic'], predicted_full_classes['predicted_classes'])\n",
    "distilBert_base_f1 = f1_score(bert_data_base['toxic'], bert_data_base['predicted_classes_base'])\n",
    "distilBert_fit_f1 = f1_score(bert_data_fit['toxic'], bert_data_fit['predicted_classes_fit'])\n",
    "\n",
    "total_table = pd.DataFrame({'DistilBert_base_f1':distilBert_base_f1,\n",
    "                            'DistilBert_fit_f1':distilBert_fit_f1,\n",
    "                            'DistilBert_full_f1':distilBert_full_f1}, index=['f1_value'])\n",
    "\n",
    "total_table.to_csv(f'exam_fale/total_table_{SAMPLE_SIZE}_f1.csv', index='F1_score')\n",
    "total_table.T      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DistilBert_base_f1</th>\n",
       "      <td>0.731988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistilBert_fit_f1</th>\n",
       "      <td>0.891129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilBert_full_f1</th>\n",
       "      <td>0.901617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "DistilBert_base_f1  0.731988\n",
       "DistilBert_fit_f1   0.891129\n",
       "distilBert_full_f1  0.901617"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_table = pd.read_csv('exam_fale/total_table_s5000_f1.csv')\n",
    "total_table.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Огонь! Молодец, что смог разобраться с обучением\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### вывод\n",
    "По качеству модели `DistilBertForSequenceClassification` можно сделать вывод, что до обученная модель<br>\n",
    "На небольшом количестве текстов классифицировала с невысоким качеством f1 `0.731988`<br>\n",
    "Количество текстов для обучения модели в этом примере было 4000 <br>\n",
    "Модель обученная на 80% от корпуса текстов показывает лучший результат классифицируя небольшой корпус текстов `0.891129`<br>\n",
    "Качество классификации всего корпуса показало лучший результат `0.901617`<br>\n",
    "\n",
    "Хочется заметить, что выборка для обучения модели на не большом корпусе и выборка которую модель классифицировала <br>\n",
    "Намеренно были выбраны случайным образом, для чистоты эксперимента<br>\n",
    "\n",
    "До обучение нейронной сети провожу в первый раз и меня терзает сомнение, что вдруг дообучение модели <br>\n",
    "На 80% от корпуса текста и последующее классифицирование всего корпуса некорректно и из-за того, что модель запомнила ответы <br>\n",
    "Поэтому показала хороший результат<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.3 ms, sys: 5.43 ms, total: 62.7 ms\n",
      "Wall time: 63.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dir_optuna = dir_make('optuna_cv')\n",
    "X = bert_data['lemma_text']\n",
    "y = bert_data['toxic']\n",
    "\n",
    "# Делим на выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Отлично, молодец, верно используешь Tfidf.\n",
    "    \n",
    "    \n",
    "Совет: Внутри кросс-валидации происходит разбиение выборки на train и valid. Однако, в таком случае векторизатор обучен на всей выборке(train), а это не совсем корректно. Чтобы избежать это можно воспользоваться Pipeline:\n",
    "    \n",
    "```python\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('logreg', LogisticRegression(random_state=42)),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'logreg__C': [1,2,6]\n",
    "}\n",
    "\n",
    "grid_search_tune = RandomizedSearchCV(pipeline, parameters, cv=3, n_jobs=-1, scoring='f1', verbose=3)\n",
    "grid_search_tune.fit(train_features, train_targets)\n",
    "  \n",
    "    \n",
    "```\n",
    "    \n",
    "Это просто каркас, можешь сам выбрать какие параметры использовать для подбора:) \n",
    "    \n",
    "+  https://runebook.dev/ru/docs/scikit_learn/modules/generated/sklearn.model_selection.halvinggridsearchcv - тут про HalvingGridSearchCV\n",
    "    \n",
    "+  https://www.rupython.com/python-sklearn-pipeline-pipeline-28301.html - про pipeline\n",
    "+  https://towardsdatascience.com/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совет: Внутри кросс-валидации происходит разбиение выборки на train и valid. Однако, в таком случае векторизатор обучен на всей выборке(train), а это не совсем корректно. Чтобы избежать это можно воспользоваться Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем функцию для оптимизации\n",
    "def objective(trial, X_train_tfidf, y_train):\n",
    "    # Параметры для Logistic Regression\n",
    "    C = trial.suggest_loguniform('C', 1e-5, 100)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 10000)\n",
    "    \n",
    "    # Обучаем модель\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('model', LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=max_iter, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    \n",
    "    cv = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scoring =  {'f1': make_scorer(f1_score)}\n",
    "    scores = cross_validate(pipeline, X_train, y_train, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "\n",
    "    # Возвращаем метрику качества F1\n",
    "    return scores['test_f1'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера ⚠️:</b> Так, а у LogisticRegression есть гиперпараметр device? \n",
    "    \n",
    "    \n",
    "Можно было сделатьт без make_scorer, `scoring='f1'`\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: black; background-color: #FFC373; padding: 10px 20px;\">\n",
    "    \n",
    "Поправил)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> За optuna лайк\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-14 03:12:47,399]\u001b[0m A new study created in memory with name: no-name-0527535a-d721-4680-8087-9b7893600b3c\u001b[0m\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-14 03:12:57,366]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'C': 0.00012585331179464763, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 7716}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      " 17%|███████▌                                     | 1/6 [00:09<00:49,  9.98s/it]\u001b[32m[I 2023-04-14 03:13:01,776]\u001b[0m Trial 1 finished with value: 0.20115758082730364 and parameters: {'C': 0.02184476506790699, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 1470}. Best is trial 1 with value: 0.20115758082730364.\u001b[0m\n",
      " 33%|███████████████                              | 2/6 [00:14<00:26,  6.70s/it]\u001b[32m[I 2023-04-14 03:13:06,598]\u001b[0m Trial 2 finished with value: 0.773072044082003 and parameters: {'C': 6.510865598283427, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 9660}. Best is trial 2 with value: 0.773072044082003.\u001b[0m\n",
      " 50%|██████████████████████▌                      | 3/6 [00:19<00:17,  5.84s/it]\u001b[32m[I 2023-04-14 03:13:10,623]\u001b[0m Trial 3 finished with value: 0.42676788021840095 and parameters: {'C': 0.07428345795217281, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 9059}. Best is trial 2 with value: 0.773072044082003.\u001b[0m\n",
      " 67%|██████████████████████████████               | 4/6 [00:23<00:10,  5.12s/it]\u001b[32m[I 2023-04-14 03:13:14,521]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'C': 0.0003083273382474079, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 5397}. Best is trial 2 with value: 0.773072044082003.\u001b[0m\n",
      " 83%|█████████████████████████████████████▌       | 5/6 [00:27<00:04,  4.68s/it]\u001b[32m[I 2023-04-14 03:13:29,119]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'C': 3.1655436712143195e-05, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 6640}. Best is trial 2 with value: 0.773072044082003.\u001b[0m\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:41<00:00,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение F1: 0.7731\n",
      "Лучшие параметры: {'C': 6.510865598283427, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 9660}\n",
      "CPU times: user 1.08 s, sys: 585 ms, total: 1.67 s\n",
      "Wall time: 41.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Запускаем оптимизацию\n",
    "study = optuna.create_study(direction='maximize')\n",
    "n_trials = 6\n",
    "trials_data = []\n",
    "\n",
    "with tqdm(total=n_trials) as pbar:\n",
    "    for i in range(n_trials):\n",
    "        study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=1)\n",
    "        trials_data.append(study.trials_dataframe().tail(1))\n",
    "        pbar.update(1)\n",
    "        \n",
    "            \n",
    "# Сохраняем оставшиеся результаты в файл\n",
    "df = pd.concat(trials_data, ignore_index=True)\n",
    "df.to_csv(f'{dir_optuna}/trials_data.csv', index=False)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(f'Лучшее значение F1: {study.best_value:.4f}')\n",
    "print(f'Лучшие параметры: {study.best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> \n",
    "Угу, хороший результат:)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9493\n",
      "F1 Score: 0.7684\n",
      "CPU times: user 6.26 s, sys: 1.2 s, total: 7.47 s\n",
      "Wall time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Обучаем модель с лучшими параметрами на всем тренировочном наборе данных\n",
    "best_params = study.best_params\n",
    "model = LogisticRegression(**best_params,  class_weight='balanced', random_state=RANDOM_STATE)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Получаем прогнозы на тестовом наборе данных и вычисляем метрики качества\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'Accuracy: {acc:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель `LogisticRegression` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DistilBert_base_f1</th>\n",
       "      <td>0.731988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistilBert_fit_f1</th>\n",
       "      <td>0.891129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilBert_full_f1</th>\n",
       "      <td>0.901617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.768423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "DistilBert_base_f1  0.731988\n",
       "DistilBert_fit_f1   0.891129\n",
       "distilBert_full_f1  0.901617\n",
       "LogisticRegression  0.768423"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_table['LogisticRegression'] = f1\n",
    "total_table.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Верно протестировал:) Получил хороший результат\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### вывод\n",
    "Модель `LogisticRegression` показала качество на тестовой выборке удовлетворяющее заданным параметрам `0.774213`<br>\n",
    "Также стоит отметить, что скорость обучения модели на 80% от всего корпуса с TF-IDF текста во много раз превосходят <br>\n",
    "Скорость обучения `DistilBertForSequenceClassification`<br>\n",
    "<br>\n",
    "Для улучшения качества модели были предприняты попытки по балансировки классов с использованием методов `Downsampling, SMOTE, ADASYN`<br>\n",
    "Но не один из методов не принес желаемого результата, во всех случаях качество модели во время подбора гипер параметров<br>\n",
    "Было высокое, но на тестовых данных оказывалось меньше чем в базовом решение<br> \n",
    "Что свидетельствовало о том, что модель переобучилась на тренировочных данных, что привело к плохой обобщающей способности и<br> \n",
    "Плохому качеству на тестовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы финал\n",
    "\n",
    "\n",
    "Результатом выполнения работы стало подготовка модели `DistilBertForSequenceClassification` пред обученной для бинарной классификации <br>\n",
    "И до обученной на предоставленном для работы корпусе текстов<br>\n",
    "Конфигурационные файлы модели находятся в директории `files_from_drive` и готовы для использования<br>\n",
    "Это файл конфигурации `config_epoch_3_drive.json` и файл с весами модели `model_epoch_3_drive.pth`<br>\n",
    "Финальное качество модели по метрике f1 = `0.901617`<br>\n",
    "\n",
    "\n",
    "Для выполнения работы заказчик предоставил csv файл с тремя столбцами `Unnamed: 0, text, toxic`<br>\n",
    "Столбец `Unnamed: 0` удалили <br>\n",
    "Столбец `text` это признак, столбец `toxic` целевой признак <br>\n",
    "\n",
    "Отфильтровали все тексты длина которых превышала 512токенов<br>\n",
    "Для балансировки целевого признака использовали метод `class_weight`\n",
    "Корпус текста обработали с лемматизацией и без<br>\n",
    "Текст без лемматизации для модели BERT<br>\n",
    "Текст с лемматизацией для построения векторов TF-IDF в sklearn<br>\n",
    "Обработанный текс сохранили в  файл `processed_data.csv`<br>\n",
    "\n",
    "\n",
    "По качеству модели `DistilBertForSequenceClassification` можно сделать вывод, что до обученная модель<br>\n",
    "На небольшом количестве текстов классифицировала с невысоким качеством f1 `0.731988`<br>\n",
    "Количество текстов для обучения модели в этом примере было 4000 <br>\n",
    "Модель обученная на 80% от корпуса текстов показывает лучший результат `0.901617`<br>\n",
    "\n",
    "\n",
    "Модель `LogisticRegression` показала качество на тестовой выборке удовлетворяющее заданным параметрам `0.774213`<br>\n",
    "Также стоит отметить, что скорость обучения модели на 80% от всего корпуса с TF-IDF текста во много раз превосходят <br>\n",
    "Скорость обучения `DistilBertForSequenceClassification`<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> \n",
    "\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множество реализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Итоговый комментарий ревьюера</b></font>\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b>Ларин, спасибо за хороший проект!!! Я готов принять работу, но хочу убедиться, что тебе все понятно.<br>\n",
    "Если есть какие либо вопросы я с удовольствием на них отвечу:)</div>\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 53,
    "start_time": "2023-04-13T19:48:18.969Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
