{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цель\n",
    "\n",
    "Для интернет-магазина \"Викишоп\" подготовить модель фильтрации комментариев и описания товаров<br>\n",
    "Модель должна классифицировать тексты определяя эмоциональный окрас позитивный или негативный <br>\n",
    "<br>\n",
    "Критерий оценки качества модели метрика F1, допустимые минимальные значения 0.75<br>\n",
    "Данные находятся по ссылке https://code.s3.yandex.net/datasets/toxic_comments.csv<br>\n",
    "В файле два столбца `text и toxic` <br>\n",
    "Признаки находятся в столбце `text`<br>\n",
    "Целевой признак `toxic`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/maximlarin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/maximlarin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "capture": "ExecutionMagics",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "markdown": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autoawait": "AsyncMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cat": "Other",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "colors": "BasicMagics",
        "conda": "PackagingMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "cp": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "lf": "Other",
        "lk": "Other",
        "ll": "Other",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "lx": "Other",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "man": "KernelMagics",
        "matplotlib": "PylabMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "mv": "Other",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "pip": "PackagingMagics",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rm": "Other",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "store": "StoreMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %colors  %conda  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%capture  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import torch\n",
    "import requests\n",
    "import transformers \n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, DistilBertConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Загрузка стоп-слов\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import  f1_score, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "    optuna_loaded = True\n",
    "except:\n",
    "    !pip install optuna\n",
    "    import optuna\n",
    "\n",
    "\n",
    "try:\n",
    "    import pkg_resources\n",
    "    pkg_resources_loaded = True\n",
    "except:\n",
    "    !pip install pkg_resources\n",
    "    import optuna  \n",
    "\n",
    "\n",
    "%lsmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека `transformers` версии 4.12.5 требует версию `protobuf` 3.19.0 или меньше, и может не работать с более новыми версиями `protobuf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U protobuf==3.19.0\n",
    "\n",
    "if pkg_resources.get_distribution(\"protobuf\").version < '3.19.0':\n",
    "    !pip install -U protobuf==3.19.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaded = False\n",
    "try:\n",
    "    data = pd.read_csv('toxic_comments.csv')\n",
    "    data_loaded = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if not data_loaded:\n",
    "    data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим константы\n",
    "NAME_DATA = 'toxic_commens'\n",
    "RANDOM_STATE = 6568\n",
    "SAMPLE_SIZE = 5000 # Размер выборки корпуса - 1000 на i5 общитывает на cpu ≈ 60 мин\n",
    "                    # на gpu ≈ 5 мин\n",
    "                     # Размер выборки корпуса - 5000 на i5 общитывает на cpu ≈ 11 часов\n",
    "                    # на gpu ≈ 60 мин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения работы мы будем использовать модель DistilBertForSequenceClassification<br>\n",
    "Модель принимает на вход векторы максимальной длины 512 токенов <br>\n",
    "Посчитаем сколько текстов превышает эту величину и отфильтруем корпус текстов<br>\n",
    "Это поможет избежать танца с бубном вокруг подачи на вход векторов для модели DistilBertForSequenceClassification  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент текстов от общей длины корпуса с размером больше 512 токенов 1.74%\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем токенизатор\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "# Токенизируем каждый текст и подсчитываем количество слов\n",
    "data['word_count'] = data['text'].apply(lambda x: len(tokenizer.tokenize(x.lower())))\n",
    "\n",
    "long_text = (data.loc[data['word_count'] >= 512]['word_count']).count()\n",
    "print(f'Процент текстов от общей длины корпуса с размером больше 512 токенов {long_text/data.shape[0]:,.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, смело можем отсечь эти тексты так как их количество невелико "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['word_count'] < 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isna_count_procent(data, name):\n",
    "    '''\n",
    "    Создадим таблицу с пропусками в  дата сете\n",
    "    Всего три столбца \n",
    "    1. процентное отношение пропусков к длине\n",
    "    2. количество пропусков в единицах\n",
    "    3. тип\n",
    "    Далее блок выводит всю доступную информацию о данных \n",
    "    Несколько первых строк\n",
    "    Описание числовых признаков\n",
    "    Описание категориальных признаков\n",
    "    \n",
    "    '''\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    isna_columns = data.isna().sum() > 0\n",
    "    type_ = pd.DataFrame(data[data.isna().sum()[isna_columns].index.tolist()].dtypes)[0]\n",
    "    isna_columns = pd.DataFrame([data.isna().sum()[isna_columns]/data.shape[0], data.isna().sum()[isna_columns]]).T\n",
    "    isna_columns = isna_columns.rename(columns={0: 'procent', 1: 'count'})\n",
    "    # isna_columns['type'] = type_[0]\n",
    "    isna_columns['count'] = isna_columns['count'].map('{:,.2f}'.format)\n",
    "    isna_columns['procent'] = isna_columns['procent'].map('{:,.2%}'.format)\n",
    "    isna_columns = isna_columns.sort_values('procent', ascending=False)\n",
    "    # блок показывае всё о данных\n",
    "    display(data.head())\n",
    "    print('#'*55)\n",
    "    print()\n",
    "    display(data.describe(include=np.number))\n",
    "    print()\n",
    "    display(data.describe(include=np.object_))\n",
    "    print('#'*55)\n",
    "    print()\n",
    "    data.info()\n",
    "    print('#'*55)\n",
    "    isna = data.isna().sum().sum()\n",
    "    isna_procent = len(isna_columns)/data.shape[1]\n",
    "    s = data.duplicated().sum()\n",
    "    print(f'Количество дубликатов в данных  равно {s}')\n",
    "    print()\n",
    "    print(f'Всего пропусков в {name} {isna:,} шт. в {len(isna_columns)} столбцах')\n",
    "    print(f'В процентном отношении {isna_procent:.2%} от {data.shape[1]:,} признаков')\n",
    "  \n",
    "    print()\n",
    "    display(isna_columns)\n",
    "    return isna_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isna_count_procent(data, NAME_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных два столбца которые мы ожидали увидеть и <br>\n",
    "Третий столбец о которм заказчик нас не предупредил<br>\n",
    "Проверим является ли столбец `Unnamed: 0` индексом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Столбец не является непрерывным.\n"
     ]
    }
   ],
   "source": [
    "column_array = np.array(data['Unnamed: 0'])\n",
    "\n",
    "# Вычисление разностей между элементами массива\n",
    "diff_array = np.diff(column_array)\n",
    "\n",
    "# Проверка на непрерывность\n",
    "if np.all(diff_array == 1):\n",
    "    print(\"Столбец является непрерывным.\")\n",
    "else:\n",
    "    print(\"Столбец не является непрерывным.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация в столбце `Unnamed: 0` не понятна ценности для выполнения задания не составляет<br>\n",
    "Удалим этот столбец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns='Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['text.color'] = 'black'\n",
    "\n",
    "fig, (ax1) = plt.subplots( figsize=(8,6));\n",
    "fig.patch.set_facecolor('#A0DFE2')\n",
    "data['toxic'].value_counts().plot.pie( labels=None, ylabel='', autopct='%1.2f%%', legend=True, ax=ax1);\n",
    "ax1.legend(['положительный', 'отрицательный'],loc='lower left');\n",
    "ax1.set_title('Количество положительных и отрицательных текстов');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевой признак имеет большую диспропорцию, при разбиении на обучающую и проверочную выборки обязательно <br>\n",
    "Выполнить балансировку классов\n",
    "\n",
    "Для выполнения нашего проекта нам понадобиться причесанный текс в двух конфигурациях<br>\n",
    "В одной без лемматизации для модели BERT<br>\n",
    "В другой с лемматизацией для построения векторов TF-IDF в sklearn<br>\n",
    "Напишем функцию, выполним обработку текста и сохраним результат в файл csv <br>\n",
    "В дальнейшем будем инициировать корпус из подготовленного файла<br>\n",
    "\n",
    "Это поможет избежать многократной обработки и ускорит выполнение проекта<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text, lemma=True):\n",
    "    # Проверка на тип строки\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    \n",
    "    # Удаление знаков препинания\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Приведение текста к нижнему регистру\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Токенизация текста\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Оптимизация: кэширование множества стоп-слов\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Фильтрация стоп-слов и лемматизация текста (если значение lemma равно True)\n",
    "    stemmer = SnowballStemmer('english') if lemma else None\n",
    "    filtered_tokens = []\n",
    "    for word in tokens:\n",
    "        if word not in stop_words:\n",
    "            if stemmer is not None:\n",
    "                word = stemmer.stem(word)\n",
    "            filtered_tokens.append(word)\n",
    "    \n",
    "    text = ' '.join(filtered_tokens)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data['processed_text'] = data['text'].apply(preprocess_text, lemma=False)\n",
    "data['lemma_text'] = data['text'].apply(preprocess_text, lemma=True)\n",
    "\n",
    "filtered_data = data[(data['processed_text'].notnull()) & (data['processed_text']!='') & \n",
    "                     (data['lemma_text'].notnull()) & (data['lemma_text']!='')].copy()\n",
    "\n",
    "\n",
    "# filtered_data.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>lemma_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>explan edit made usernam hardcor metallica fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>daww matches background colour im seemingly st...</td>\n",
       "      <td>daww match background colour im seem stuck tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>hey man im really trying edit war guy constant...</td>\n",
       "      <td>hey man im realli tri edit war guy constant re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>cant make real suggestions improvement wondere...</td>\n",
       "      <td>cant make real suggest improv wonder section s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>sir hero chance remember page thats</td>\n",
       "      <td>sir hero chanc rememb page that</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  word_count  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0          60   \n",
       "1  D'aww! He matches this background colour I'm s...      0          32   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0          50   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0         131   \n",
       "4  You, sir, are my hero. Any chance you remember...      0          19   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  explanation edits made username hardcore metal...   \n",
       "1  daww matches background colour im seemingly st...   \n",
       "2  hey man im really trying edit war guy constant...   \n",
       "3  cant make real suggestions improvement wondere...   \n",
       "4                sir hero chance remember page thats   \n",
       "\n",
       "                                          lemma_text  \n",
       "0  explan edit made usernam hardcor metallica fan...  \n",
       "1  daww match background colour im seem stuck tha...  \n",
       "2  hey man im realli tri edit war guy constant re...  \n",
       "3  cant make real suggest improv wonder section s...  \n",
       "4                    sir hero chanc rememb page that  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_data = pd.read_csv('processed_data.csv') \n",
    "\n",
    "bert_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "Для выполнения работы заказчик предоставил csv файл с тремя столбцами `Unnamed: 0, text, toxic`<br>\n",
    "Столбец `Unnamed: 0` удалили он нам не нужен для выполнения работы<br>\n",
    "Столбец `text` это признак, столбец `toxic` целевой признак <br>\n",
    "\n",
    "Для выполнения работы будем использовать модель DistilBertForSequenceClassification<br>\n",
    "Модель принимает на вход векторы максимальной длины 512 токенов <br>\n",
    "Отфильтровали все тексты длина которых превышала 512токенов<br>\n",
    "Это поможет избежать танца с бубном вокруг подачи на вход векторов для модели DistilBertForSequenceClassification  <br>\n",
    "\n",
    "Целевой признак имеет большую диспропорцию, при разбиении на обучающую и проверочную выборки, обязательно <br>\n",
    "Выполнить балансировку классов\n",
    "\n",
    "Выполнили обработку текста с лемматизацией и без<br>\n",
    "Текст без лемматизации для модели BERT<br>\n",
    "Текст с лемматизацией для построения векторов TF-IDF в sklearn<br>\n",
    "\n",
    "Подготовленный текс сохранили в  файл `processed_data.csv`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для реализации работы по созданию модели бинарной классификации используем пред обученную модель DistilBertForSequenceClassification<br>\n",
    "С сайта [huggingface.co](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)<br>\n",
    "Для неё нам понадобится причёсанный текст без лемматизации из столбца `processed_text` <br>\n",
    "Далее мы возьмем небольшой кусочек корпуса для примера того, что код работает корректо<br>\n",
    "И до обучим модель с учителем, что позволит ей лучше понять классификацию нашего корпуса<br>\n",
    "Полное обучение модели мы провели на подходящем оборудовании на сайте [kaggle](https://www.kaggle.com/code/maksimlarin/neironver2/notebook?scriptVersionId=125267350)<br>Поэтому для примера нам хватит небольшого количества текстов<br>\n",
    "Далее для классификации будем инициировать модель и её конфигурационный файл из сохранённых после полного обучения файлов "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция создаёт директории \n",
    "def dir_make(dir_name):\n",
    "     # определим путь к директории\n",
    "    directory = os.path.abspath(dir_name)\n",
    "\n",
    "    # проверим, существует ли директория, и создадим ее, если это необходимо\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    return directory \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Выберем не много для примера\n",
    "bert_data_base = bert_data[['processed_text', 'toxic']].sample(n=SAMPLE_SIZE, replace=False).reset_index(drop=True).copy()\n",
    "\n",
    "bert_data_base.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициируем модель `DistilBertForSequenceClassification`, токенизатор и определитель устройства для расчетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделение на тренировочный и тестовый наборы данных\n",
    "train_data, test_data = train_test_split(bert_data_base, test_size=0.2, random_state=42, stratify=bert_data_base['toxic'])\n",
    "\n",
    "train_data_token = tokenizer.batch_encode_plus(train_data['processed_text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "test_data_token = tokenizer.batch_encode_plus(test_data['processed_text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# объединение закодированных тензоров и меток в один TensorDataset\n",
    "dataset_train_data = TensorDataset(train_data_token['input_ids'], train_data_token['attention_mask'], torch.tensor(train_data['toxic'].values))\n",
    "dataset_test_data = TensorDataset(test_data_token['input_ids'], test_data_token['attention_mask'], torch.tensor(test_data['toxic'].values))\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=2, num_training_steps=len(train_data)*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация DataLoader\n",
    "batch_size = 20 # количество элементов в батче\n",
    "train_loader = DataLoader(dataset_train_data, batch_size=batch_size)\n",
    "model.to(device)\n",
    "\n",
    "# цикл обучения\n",
    "for epoch in range(3):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm(train_loader):\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "       \n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print('Epoch:', epoch+1, 'Training Loss:', f'{avg_train_loss:,.3f}')\n",
    "   \n",
    "    test_loader = DataLoader(dataset_test_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for batch in tqdm(test_loader):\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predicted_label = torch.argmax(outputs[0], dim=1).cpu().numpy()\n",
    "            true_label = labels\n",
    "            y_pred.extend(predicted_label.tolist())\n",
    "            y_true.extend(true_label.tolist())\n",
    "\n",
    "        print('Epoch:', epoch+1, 'F1:', f'{f1_score(y_true, y_pred):,.3f}')\n",
    "        \n",
    "        \n",
    "exam_fale = dir_make('exam_fale')\n",
    "        \n",
    "model.to(torch.device('cpu'))\n",
    "model_file = os.path.join(exam_fale, \"model_epoch_3_exam.pth\")\n",
    "torch.save(model.state_dict(), model_file)\n",
    "\n",
    "\n",
    "# Сохранение конфигурации модели\n",
    "\n",
    "config_file = os.path.join(exam_fale, \"config_epoch_3_exam.jso\")\n",
    "model.config.to_json_file(config_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель `DistilBertForSequenceClassification` до обучили на небольшой выборке подготовленных текстов<br>\n",
    "Напишем функцию классификации текста, она принимает на вход модель, таблицу с подготовленным текстом и таргетом<br>\n",
    "Возвращает туже таблицу с новым столбцом значение которого это классификация предсказанная моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classifiction_corpus(model, processed_text, column_name):    \n",
    "    encoded_texts = (tokenizer.batch_encode_plus(processed_text['processed_text'].tolist(), \n",
    "                                                 padding=True, truncation=True, return_tensors='pt').to(device))\n",
    "\n",
    "    batch_size = 10\n",
    "\n",
    "    # Инициализация пустого тензора для хранения предсказанных классов\n",
    "    predicted_classes = torch.empty((len(encoded_texts['input_ids']),), dtype=torch.long)\n",
    "    model.to(device)\n",
    "    # Передача данных порциями в модель\n",
    "    for i in tqdm(range(0, len(encoded_texts['input_ids']), batch_size)):\n",
    "        inputs_pred = {\n",
    "            'input_ids': encoded_texts['input_ids'][i:i+batch_size],\n",
    "            'attention_mask': encoded_texts['attention_mask'][i:i+batch_size],\n",
    "        }\n",
    "        outputs_pred = model(**inputs_pred)\n",
    "\n",
    "        batch_predicted_classes = torch.argmax(outputs_pred.logits, dim=-1)\n",
    "        predicted_classes[i:i+batch_size] = batch_predicted_classes\n",
    "\n",
    "    processed_text[column_name] = torch.tensor(predicted_classes).cpu().to(torch.long)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним классификацию до обученной моделью `DistilBertForSequenceClassification` на небольшом корпусе текстов<br>\n",
    "Который выберем случайным образом из генерального корпуса, для чистоты эксперимента "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Выберем не много для примера\n",
    "bert_data_base = bert_data[['processed_text', 'toxic']].sample(n=SAMPLE_SIZE, replace=False).reset_index(drop=True).copy()\n",
    "\n",
    "bert_data_base = classifiction_corpus(model, bert_data_base, 'predicted_classes_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы до обучили модель DistilBertForSequenceClassification на небольшом корпусе текста для примера<br>\n",
    "И получили конфигурационный файл модели `config_epoch_3_exam.jso` и файл с весами `model_epoch_3_exam.pth`<br>\n",
    "Файлы поместили в директорию `exam_fale`<br>\n",
    "Полное до обучение модели выполнили на сайте `kaggle` и уже имеем готовые конфигурационные файлы<br>\n",
    "Которые будем использовать для инициализации модели<br>\n",
    "Notebook с полным дообучением можно посмотреть по ссылке [kaggle notebook continuing education](https://www.kaggle.com/code/maksimlarin/neironver2/notebook)<br>\n",
    "Файлы конфигурации находятся на google disk и для того, что бы их от туда взять напишем функцию парсера и создадим директорию для файлов<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция скачивает файлы конфигурвции с google drive\n",
    "def drive_parser(url, fale_name, dir_name):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    download_form = soup.find('form', {'id': 'download-form'})\n",
    "    download_url = download_form.attrs['action']\n",
    "\n",
    "    data = {}\n",
    "    for input_tag in download_form.find_all('input'):\n",
    "        name = input_tag.attrs.get('name')\n",
    "        value = input_tag.attrs.get('value')\n",
    "        if name and value:\n",
    "            data[name] = value\n",
    "\n",
    "    response = requests.post(download_url, data=data)\n",
    "\n",
    "     #  путь к директории\n",
    "    directory = dir_make(dir_name)\n",
    "\n",
    "        # сохраним файл в директории\n",
    "    with open(os.path.join(directory, fale_name), 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция скачивает файлы конфигурвции с google drive\n",
    "def get_json(url, fale_name, dir_name):\n",
    "    \n",
    "     # определим путь к директории\n",
    "    directory = dir_make(dir_name)\n",
    "\n",
    "    # отправим GET-запрос к URL-адресу файла\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # сохраним содержимое файла\n",
    "    with open(os.path.join(directory, fale_name), 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим репозиторий `files_from_drive`, скачаем в него файлы конфигурации модели которые получили после до обучения <br>\n",
    "Модели DistilBertForSequenceClassification на полном корпусе текстов<br>\n",
    "Инициируем модель с конфигурацией которую скачали и выполним классификацию текстов для сравнения<br>\n",
    "Качества до обученной модели на не большом корпусе и качество F1 которую показала модель <br>\n",
    "До обученная на 80% от полного корпуса текстов классифицируя полный корпус текста<br>\n",
    "Полную классификацию текста с до обученной моделью выполнили на сайте `Keggle`<br>\n",
    "Ноутбук с работой доступен по ссылке [kaggle классификация полного корпуса](https://www.kaggle.com/code/maksimlarin/building-f1)<br><br>\n",
    "Инициируем переменную с названием директории для скачивания готовой конфигурации<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dir_name = 'files_from_drive'\n",
    "\n",
    "drive_parser('https://drive.google.com/u/0/uc?id=1VJ6qTSLny5wkwsLon41_nqZazi-Jf2UD&export=download', 'model_epoch_3_drive.pth', dir_name)\n",
    "drive_parser('https://drive.google.com/uc?id=1H0lZAmi5Dq-Yi7j9QSjvADWxzxWz9Dhl&export=download', 'processed_data_drive.csv', dir_name)\n",
    "get_json('https://drive.google.com/uc?id=1cZUpJ1odjfqdSskpTiHqc9COOBvz39Im&export=download', 'config_epoch_3_drive.json', dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициируем модель `DistilBertForSequenceClassification` с готовой конфигурацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_model = 'files_from_drive/model_epoch_3_drive.pth' #  путь к файлу \n",
    "\n",
    "path_to_config = 'files_from_drive/config_epoch_3_drive.json' #  путь к файлу \n",
    "with open(path_to_config, 'r') as f:\n",
    "    config_dict = json.load(f)\n",
    "config = DistilBertConfig.from_dict(config_dict)\n",
    "\n",
    "# Создание модели на основе файла конфигурации и загруженных весов\n",
    "model_ful = DistilBertForSequenceClassification(config=config)\n",
    "model_ful.load_state_dict(torch.load(path_to_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним классификацию до обученной моделью DistilBertForSequenceClassification на маленьком корпусе текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Выберем не много для примера\n",
    "bert_data_fit = bert_data[['processed_text', 'toxic']].sample(n=SAMPLE_SIZE, replace=False).reset_index(drop=True).copy()\n",
    "\n",
    "\n",
    "bert_data_fit = classifiction_corpus(model_ful, bert_data_fit, 'predicted_classes_fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим таблицу с классификацией по полному корпусу<br>\n",
    "Посчитаем качество модели используя метрику f1 и заполним финальную таблицу с результатом<br>\n",
    "Для модели до обученной на небольшом корпусе текстов<br>\n",
    "Для модели обученной на 80% от всего корпуса и выполняющей классификацию небольшого корпусе<br>\n",
    "Для модели обученной на 80% от всего корпуса и выполняющей классификацию полного корпуса текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_full_classes = pd.read_csv('files_from_drive/processed_data_drive.csv')\n",
    "\n",
    "\n",
    "distilBert_full_f1 = f1_score(predicted_full_classes['toxic'], predicted_full_classes['predicted_classes'])\n",
    "distilBert_base_f1 = f1_score(bert_data_base['toxic'], bert_data_base['predicted_classes_base'])\n",
    "distilBert_fit_f1 = f1_score(bert_data_fit['toxic'], bert_data_fit['predicted_classes_fit'])\n",
    "\n",
    "total_table = pd.DataFrame({'DistilBert_base_f1':distilBert_base_f1,\n",
    "                            'DistilBert_fit_f1':distilBert_fit_f1,\n",
    "                            'DistilBert_full_f1':distilBert_full_f1}, index=['f1_value'])\n",
    "\n",
    "total_table.to_csv(f'exam_fale/total_table_{SAMPLE_SIZE}_f1.csv', index=False)\n",
    "total_table.T      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DistilBert_base_f1</th>\n",
       "      <td>0.731988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistilBert_fit_f1</th>\n",
       "      <td>0.891129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilBert_full_f1</th>\n",
       "      <td>0.901617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "DistilBert_base_f1  0.731988\n",
       "DistilBert_fit_f1   0.891129\n",
       "distilBert_full_f1  0.901617"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_table = pd.read_csv('exam_fale/total_table_s5000_f1.csv')\n",
    "total_table.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### вывод\n",
    "По качеству модели `DistilBertForSequenceClassification` можно сделать вывод, что до обученная модель<br>\n",
    "На небольшом количестве текстов классифицировала с невысоким качеством f1 `0.731988`<br>\n",
    "Количество текстов для обучения модели в этом примере было 4000 <br>\n",
    "Модель обученная на 80% от корпуса текстов показывает лучший результат классифицируя небольшой корпус текстов `0.891129`<br>\n",
    "Качество классификации всего корпуса показало лучший результат `0.901617`<br>\n",
    "\n",
    "Хочется заметить, что выборка для обучения модели на не большом корпусе и выборка которую модель классифицировала <br>\n",
    "Намеренно были выбраны случайным образом, для чистоты эксперимента<br>\n",
    "\n",
    "До обучение нейронной сети провожу в первый раз и меня терзает сомнение, что вдруг дообучение модели <br>\n",
    "На 80% от корпуса текста и последующее классифицирование всего корпуса некорректно и из-за того, что модель запомнила ответы <br>\n",
    "Поэтому показала хороший результат<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.1 ms, sys: 4.92 ms, total: 62 ms\n",
      "Wall time: 61.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dir_optuna = dir_make('optuna_cv')\n",
    "X = bert_data['lemma_text']\n",
    "y = bert_data['toxic']\n",
    "\n",
    "# Делим на выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем функцию для оптимизации\n",
    "def objective(trial, X_train_tfidf, y_train):\n",
    "    # Параметры для Logistic Regression\n",
    "    C = trial.suggest_loguniform('C', 1e-5, 100)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 10000)\n",
    "    \n",
    "    # Выбираем устройство\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Обучаем модель\n",
    "    if device.type == 'cuda':\n",
    "        model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=max_iter, random_state=RANDOM_STATE,  device=device)\n",
    "    else:\n",
    "        model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=max_iter, random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "    # Обучаем модель\n",
    "    model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=max_iter, random_state=RANDOM_STATE)\n",
    "    cv = KFold(n_splits=2, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scoring = {'f1': make_scorer(f1_score)}\n",
    "    scores = cross_validate(model, X_train_tfidf, y_train, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "\n",
    "    # Возвращаем метрику качества F1\n",
    "    return scores['test_f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 23:26:09,278]\u001b[0m A new study created in memory with name: no-name-5ee49abf-38ae-4abf-9956-b5a16eecbc6b\u001b[0m\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[32m[I 2023-04-12 23:26:10,737]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'C': 3.6616189975491755e-05, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 7845}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      " 20%|█████████                                    | 1/5 [00:01<00:05,  1.44s/it]\u001b[32m[I 2023-04-12 23:26:11,786]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'C': 0.0007238491610565659, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 346}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      " 40%|██████████████████                           | 2/5 [00:02<00:03,  1.20s/it]\u001b[32m[I 2023-04-12 23:26:12,863]\u001b[0m Trial 2 finished with value: 0.24351800837441892 and parameters: {'C': 0.009160442455601677, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 4602}. Best is trial 2 with value: 0.24351800837441892.\u001b[0m\n",
      " 60%|███████████████████████████                  | 3/5 [00:03<00:02,  1.15s/it]\u001b[32m[I 2023-04-12 23:26:14,672]\u001b[0m Trial 3 finished with value: 0.7538836538971923 and parameters: {'C': 33.03520314969812, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 9211}. Best is trial 3 with value: 0.7538836538971923.\u001b[0m\n",
      " 80%|████████████████████████████████████         | 4/5 [00:05<00:01,  1.41s/it]\u001b[32m[I 2023-04-12 23:26:29,965]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'C': 1.4049888571650789e-05, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 734}. Best is trial 3 with value: 0.7538836538971923.\u001b[0m\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:20<00:00,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение F1: 0.7539\n",
      "Лучшие параметры: {'C': 33.03520314969812, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 9211}\n",
      "CPU times: user 188 ms, sys: 246 ms, total: 434 ms\n",
      "Wall time: 20.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Запускаем оптимизацию\n",
    "study = optuna.create_study(direction='maximize')\n",
    "n_trials = 5\n",
    "trials_data = []\n",
    "\n",
    "with tqdm(total=n_trials) as pbar:\n",
    "    for i in range(n_trials):\n",
    "        study.optimize(lambda trial: objective(trial, X_train_tfidf, y_train), n_trials=1)\n",
    "        trials_data.append(study.trials_dataframe().tail(1))\n",
    "        pbar.update(1)\n",
    "        \n",
    "            \n",
    "# Сохраняем оставшиеся результаты в файл\n",
    "df = pd.concat(trials_data, ignore_index=True)\n",
    "df.to_csv(f'{dir_optuna}/trials_data.csv', index=False)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(f'Лучшее значение F1: {study.best_value:.4f}')\n",
    "print(f'Лучшие параметры: {study.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9499\n",
      "F1 Score: 0.7645\n",
      "CPU times: user 9.86 s, sys: 1.6 s, total: 11.5 s\n",
      "Wall time: 3.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Обучаем модель с лучшими параметрами на всем тренировочном наборе данных\n",
    "best_params = study.best_params\n",
    "model = LogisticRegression(**best_params,  class_weight='balanced', random_state=RANDOM_STATE)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Получаем прогнозы на тестовом наборе данных и вычисляем метрики качества\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'Accuracy: {acc:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель `LogisticRegression` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DistilBert_base_f1</th>\n",
       "      <td>0.731988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistilBert_fit_f1</th>\n",
       "      <td>0.891129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilBert_full_f1</th>\n",
       "      <td>0.901617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.764520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "DistilBert_base_f1  0.731988\n",
       "DistilBert_fit_f1   0.891129\n",
       "distilBert_full_f1  0.901617\n",
       "LogisticRegression  0.764520"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_table['LogisticRegression'] = f1\n",
    "total_table.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### вывод\n",
    "Модель `LogisticRegression` показала качество на тестовой выборке удовлетворяющее заданным параметрам `0.774213`<br>\n",
    "Также стоит отметить, что скорость обучения модели на 80% от всего корпуса с TF-IDF текста во много раз превосходят <br>\n",
    "Скорость обучения `DistilBertForSequenceClassification`<br>\n",
    "<br>\n",
    "Для улучшения качества модели были предприняты попытки по балансировки классов с использованием методов `Downsampling, SMOTE, ADASYN`<br>\n",
    "Но не один из методов не принес желаемого результата, во всех случаях качество модели во время подбора гипер параметров<br>\n",
    "Было высокое, но на тестовых данных оказывалось меньше чем в базовом решение<br> \n",
    "Что свидетельствовало о том, что модель переобучилась на тренировочных данных, что привело к плохой обобщающей способности и<br> \n",
    "Плохому качеству на тестовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы финал\n",
    "\n",
    "\n",
    "Результатом выполнения работы стало подготовка модели `DistilBertForSequenceClassification` пред обученной для бинарной классификации <br>\n",
    "И до обученной на предоставленном для работы корпусе текстов<br>\n",
    "Конфигурационные файлы модели находятся в директории `files_from_drive` и готовы для использования<br>\n",
    "Это файл конфигурации `config_epoch_3_drive.json` и файл с весами модели `model_epoch_3_drive.pth`<br>\n",
    "Финальное качество модели по метрике f1 = `0.901617`<br>\n",
    "\n",
    "\n",
    "Для выполнения работы заказчик предоставил csv файл с тремя столбцами `Unnamed: 0, text, toxic`<br>\n",
    "Столбец `Unnamed: 0` удалили <br>\n",
    "Столбец `text` это признак, столбец `toxic` целевой признак <br>\n",
    "\n",
    "Отфильтровали все тексты длина которых превышала 512токенов<br>\n",
    "Для балансировки целевого признака использовали метод `class_weight`\n",
    "Корпус текста обработали с лемматизацией и без<br>\n",
    "Текст без лемматизации для модели BERT<br>\n",
    "Текст с лемматизацией для построения векторов TF-IDF в sklearn<br>\n",
    "Обработанный текс сохранили в  файл `processed_data.csv`<br>\n",
    "\n",
    "\n",
    "По качеству модели `DistilBertForSequenceClassification` можно сделать вывод, что до обученная модель<br>\n",
    "На небольшом количестве текстов классифицировала с невысоким качеством f1 `0.731988`<br>\n",
    "Количество текстов для обучения модели в этом примере было 4000 <br>\n",
    "Модель обученная на 80% от корпуса текстов показывает лучший результат `0.901617`<br>\n",
    "\n",
    "\n",
    "Модель `LogisticRegression` показала качество на тестовой выборке удовлетворяющее заданным параметрам `0.774213`<br>\n",
    "Также стоит отметить, что скорость обучения модели на 80% от всего корпуса с TF-IDF текста во много раз превосходят <br>\n",
    "Скорость обучения `DistilBertForSequenceClassification`<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
